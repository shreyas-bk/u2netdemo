{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U_2_Netp_Cropper_Colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t13gOcRMmsC"
      },
      "source": [
        "# U-2-NETp Cropper\n",
        "\n",
        " U-2-NET Paper: [U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection](https://arxiv.org/abs/2005.09007)\n",
        " \n",
        " Repo: https://github.com/shreyas-bk/U-2-Net\n",
        "\n",
        " Original Repo: [U-2-Net Github repo](https://github.com/NathanUA/U-2-Net)\n",
        "\n",
        "References: X. Qin, Z. Zhang, C. Huang, M. Dehghan, O. R. Zaiane, and M. Jagersand, “U2-net: Going deeper with nested u-structure for salient object\n",
        "detection,” Pattern Recognition, vol. 106, p. 107404, 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC3pYV31MezF"
      },
      "source": [
        "# make sure cloned code is saved in content\n",
        "%cd /content\n",
        "\n",
        "# verify CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# clone modified version of U-2-Net\n",
        "!git clone https://github.com/shreyas-bk/U-2-Net\n",
        "\n",
        "# make images directory (to store imput images) and results (to store output images) in U-2-Net folder\n",
        "%cd /content/U-2-Net\n",
        "print('making images directory')\n",
        "!mkdir images\n",
        "print('making results directory')\n",
        "!mkdir results\n",
        "print('making cropped results directory')\n",
        "!mkdir cropped_results\n",
        "\n",
        "#import required modules\n",
        "print('importing...')\n",
        "from google.colab import files\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "from PIL import Image as Img\n",
        "import cv2\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5zn3Ib3QFJa"
      },
      "source": [
        "# Make sure runtype is GPU\n",
        "**Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEDlFFvONi5g"
      },
      "source": [
        "# change to images directory to upload image files\n",
        "%cd /content/U-2-Net/images\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ycX9cB-jdC9"
      },
      "source": [
        "# change back to U-2-Net directory\n",
        "%cd /content/U-2-Net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCG6zfBhNzAH"
      },
      "source": [
        "# run the test script, and outputs are saved to results folder\n",
        "!python -W ignore u2net_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFBODUXlk20x"
      },
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "# get the names of the images that were uploaded, removing .png\n",
        "image_dir = os.path.join(os.getcwd(), 'results/*.png')\n",
        "print(image_dir)\n",
        "file_names = glob(image_dir)\n",
        "#print(file_names)\n",
        "names = [os.path.basename(name[:-4]) for name in file_names]\n",
        "names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhwXTgx6e3mY"
      },
      "source": [
        "def process_image_named(name, threshold_cutoff = 0.90, use_transparency = False):\n",
        "  result_img = load_img('/content/U-2-Net/results/'+name+'.png')\n",
        "  # convert result-image to numpy array and rescale(255 for RBG images)\n",
        "  RESCALE = 255\n",
        "  out_img = img_to_array(result_img)\n",
        "  out_img /= RESCALE\n",
        "  # define the cutoff threshold below which, background will be removed.\n",
        "  THRESHOLD = threshold_cutoff\n",
        "\n",
        "  # refine the output\n",
        "  out_img[out_img > THRESHOLD] = 1\n",
        "  out_img[out_img <= THRESHOLD] = 0\n",
        "\n",
        "  if use_transparency:\n",
        "    # convert the rbg image to an rgba image and set the zero values to transparent\n",
        "    shape = out_img.shape\n",
        "    a_layer_init = np.ones(shape = (shape[0],shape[1],1))\n",
        "    mul_layer = np.expand_dims(out_img[:,:,0],axis=2)\n",
        "    a_layer = mul_layer*a_layer_init\n",
        "    rgba_out = np.append(out_img,a_layer,axis=2)\n",
        "    mask_img = Img.fromarray((rgba_out*RESCALE).astype('uint8'), 'RGBA')\n",
        "  else:\n",
        "    mask_img = Img.fromarray((out_img*RESCALE).astype('uint8'), 'RGB')\n",
        "\n",
        "  # load and convert input to numpy array and rescale(255 for RBG images)\n",
        "  input = load_img('/content/U-2-Net/images/'+name+'.jpg')\n",
        "  inp_img = img_to_array(input)\n",
        "  inp_img /= RESCALE\n",
        "\n",
        " \n",
        "  if use_transparency:\n",
        "    # since the output image is rgba, convert this also to rgba, but with no transparency\n",
        "    a_layer = np.ones(shape = (shape[0],shape[1],1))\n",
        "    rgba_inp = np.append(inp_img,a_layer,axis=2)\n",
        "\n",
        "    #simply multiply the 2 rgba images to remove the backgound\n",
        "    rem_back = (rgba_inp*rgba_out)\n",
        "    rem_back_scaled = Img.fromarray((rem_back*RESCALE).astype('uint8'), 'RGBA')\n",
        "  else:\n",
        "    rem_back = (inp_img*out_img)\n",
        "    rem_back_scaled = Img.fromarray((rem_back*RESCALE).astype('uint8'), 'RGB')\n",
        "\n",
        "  # select a layer(can be 0,1 or 2) for bounding box creation and salient map\n",
        "  LAYER = 2\n",
        "  out_layer = out_img[:,:,LAYER]\n",
        "\n",
        "  # find the list of points where saliency starts and ends for both axes\n",
        "  x_starts = [np.where(out_layer[i]==1)[0][0] if len(np.where(out_layer[i]==1)[0])!=0 else out_layer.shape[0]+1 for i in range(out_layer.shape[0])]\n",
        "  x_ends = [np.where(out_layer[i]==1)[0][-1] if len(np.where(out_layer[i]==1)[0])!=0 else 0 for i in range(out_layer.shape[0])]\n",
        "  y_starts = [np.where(out_layer.T[i]==1)[0][0] if len(np.where(out_layer.T[i]==1)[0])!=0 else out_layer.T.shape[0]+1 for i in range(out_layer.T.shape[0])]\n",
        "  y_ends = [np.where(out_layer.T[i]==1)[0][-1] if len(np.where(out_layer.T[i]==1)[0])!=0 else 0 for i in range(out_layer.T.shape[0])]\n",
        "  \n",
        "  # get the starting and ending coordinated for the box\n",
        "  startx = min(x_starts)\n",
        "  endx = max(x_ends)\n",
        "  starty = min(y_starts)\n",
        "  endy = max(y_ends)\n",
        "  \n",
        "  # show the resulting coordinates\n",
        "  start = (startx,starty)\n",
        "  end = (endx,endy)\n",
        "  start,end\n",
        "\n",
        "  cropped_rem_back_scaled = rem_back_scaled.crop((startx,starty,endx,endy))\n",
        "  if use_transparency:\n",
        "    cropped_rem_back_scaled.save('/content/U-2-Net/cropped_results/'+name+'_cropped_no-bg.png')\n",
        "  else:\n",
        "    cropped_rem_back_scaled.save('/content/U-2-Net/cropped_results/'+name+'_cropped_no-bg.jpg')\n",
        "  \n",
        "  cropped_mask_img = mask_img.crop((startx,starty,endx,endy))\n",
        "\n",
        "  if use_transparency:\n",
        "    cropped_mask_img.save('/content/U-2-Net/cropped_results/'+name+'_cropped_no-bg_mask.png')\n",
        "  else:\n",
        "    cropped_mask_img.save('/content/U-2-Net/cropped_results/'+name+'_cropped_no-bg_mask.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXgtai3Vi0J5"
      },
      "source": [
        "#Remove BG, Crop and save each image pair\n",
        "for name in names:\n",
        "  process_image_named(name)               #jpg, no alpha\n",
        "  #process_image_named(name, 0.9, True)   #png, with transparency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M87UaFRq5W6x"
      },
      "source": [
        "# Zip and Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcA_rbqCLJJN"
      },
      "source": [
        "%cd /content/U-2-Net/cropped_results/\n",
        "!zip /content/cropped_results.zip ./*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSOhnNb2Obgi"
      },
      "source": [
        "# download the result\n",
        "# takes a while for the progress indicator to appear\n",
        "files.download('/content/cropped_results.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}